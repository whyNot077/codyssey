{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3039a9-c515-48c6-9981-33d7ffcc42ac",
   "metadata": {},
   "source": [
    "# 추천 시스템이란\n",
    "추천 시스템은 사용자에게 개인화된 추천을 제공하기 위해 데이터 분석 및 머신러닝 기술을 활용하는 시스템이다. 이를 통해 사용자는 자신의 선호도와 행동 데이터를 기반으로 맞춤형 상품, 콘텐츠, 서비스를 추천받을 수 있다.  \n",
    "  \n",
    "잘 만들어진 추천 시스템은 사용자가 무엇을 원하는지 빠르게 찾아주기 때문에, 선택의 어려움을 줄이고 서비스 이용의 즐거움을 극대화할 수 있다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab4876c-03e9-4c0c-b98b-47b5f561301f",
   "metadata": {},
   "source": [
    "\n",
    "# 추천 시스템의 사례\n",
    "\n",
    "하나의 콘텐츠를 선택했을 때, 선택된 콘텐츠와 연관된 추천 콘텐츠가 얼마나 사용자의 관심을 끌고 개인에게 맞춘 콘텐츠를 추천했는 지는 매출과 깊게 연관되어 있다.  \n",
    "\n",
    "1. 유튜브 / 넷플릭스\n",
    "- 사용자의 시청 기록과 평점을 기반으로 관련 동영상 추천.\n",
    "\n",
    "2. 아마존\n",
    "- 상품 구매 기록과 관련된 추천 상품 제공.\n",
    "- '이 제품을 구매한 사람들이 함께 본 상품'.\n",
    "\n",
    "3. 페이스북 / 인스타그램\n",
    "- 친구, 팔로어, 관심있는 게시물 추천\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03683bb-e19c-406c-aca7-7e49604a01f9",
   "metadata": {},
   "source": [
    "\n",
    "## 1. 콘텐츠 기반 필터링(Content-Based Filtering)\n",
    "\n",
    "### (1) 특징\n",
    "- 사용자가 특정 아이템을 매우 선호하는 경우, 그 아이템과 비슷한 콘텐츠를 가진 다른 아이템을 추천.\n",
    "- 장르, 감독, 출연배우, 키워드 등을 고려하여 유사한 영화 추천.\n",
    "\n",
    "### (2) 알고리즘\n",
    "- 아이템의 속성을 기반으로 유사도를 계산.\n",
    "- 유사도 측정 방법: 코사인 유사도, 유클리드 거리 등.\n",
    "- 텍스트 데이터를 처리할 경우 TF-IDF 벡터화를 활용.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae886690-a3e1-46bb-8dde-8ec197833f0b",
   "metadata": {},
   "source": [
    "\n",
    "##### 코사인 유사도 (Cosine Similarity)\n",
    "- 두 벡터 간의 방향 유사도를 측정.\n",
    "- 영화의 속성을 벡터로 표현(예: 장르, 감독, 배우 등)한 후, 코사인 유사도를 계산하면 어떤 영화가 다른 영화와 유사한지를 알 수 있다.\n",
    "- 값의 범위: `-1`(완전히 반대) ~ `1`(완전히 동일).\n",
    "- 벡터의 크기가 아닌 방향에 초점을 맞춤.\n",
    "$$\n",
    "\\text{Cosine Similarity}(A, B) = \\frac{A \\cdot B}{||A|| \\times ||B||}\n",
    "$$\n",
    "- $A \\cdot B$: 두 벡터의 내적\n",
    "- $||A||$, $||B||$: 각 벡터의 크기\n",
    "   \n",
    "예를 들어,   \n",
    "영화 A: [1, 1, 0] (액션, 코미디, 드라마)   \n",
    "영화 B: [1, 0, 1] (액션, 드라마)   \n",
    "두 영화의 코사인 유사도가 높으면(값이 1에 가까우면), 두 영화가 비슷한 속성을 가진다고 판단하고 추천.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7ff52-a24c-46a8-800f-36b6c8371b0c",
   "metadata": {},
   "source": [
    "\n",
    "##### TF-IDF 벡터화 (Term Frequency-Inverse Document Frequency)\n",
    "- 문서 내 단어의 중요도를 측정하는 텍스트 벡터화 기법.\n",
    "- 특정 단어의 **빈도수(TF)**와 그 단어가 다른 문서에 얼마나 흔하지 않은지(**IDF**)를 결합하여 점수 계산.\n",
    "- 텍스트 데이터의 벡터화:  \n",
    "    영화의 줄거리, 키워드, 리뷰 등 텍스트 데이터를 수치로 변환하여 비교할 수 있게 한다.  \n",
    "    TF-IDF는 단순히 단어의 빈도(TF)뿐만 아니라, 특정 단어가 얼마나 **중요한지(IDF)**도 고려.   \n",
    "    예를 들어, \"action\"이라는 단어가 모든 영화 설명에 포함되어 있다면, 해당 단어의 중요도를 낮게 평가하고, 영화의 독특한 키워드에 더 높은 가중치를 부여한다.   \n",
    "- 유사성 계산:\n",
    "    TF-IDF로 영화 설명을 벡터화한 뒤, 코사인 유사도를 계산하여 설명 텍스트가 비슷한 영화를 추천\n",
    "\n",
    "     \n",
    "\n",
    "$$\n",
    "\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{IDF}(t) = \\log{\\frac{N}{1 + \\text{DF}(t)}}\n",
    "$$\n",
    "\n",
    "- $ \\text{TF}(t, d): \\text{특정 문서 } d \\text{에서 단어 } t \\text{의 등장 빈도}\n",
    "$\n",
    "\n",
    "- $\n",
    "N: \\text{전체 문서 수}\n",
    "$\n",
    "\n",
    "- $\n",
    "\\text{DF}(t): \\text{단어 } t \\text{가 등장한 문서 수}\n",
    "$\n",
    "\n",
    "\n",
    "### (3) 장점\n",
    "- 사용자 상호작용 데이터가 없어도 신규 아이템에 대한 추천이 가능(콜드 스타트 문제 해결 가능).\n",
    "- 사용자 취향에 매우 정밀한 맞춤 추천 가능.\n",
    "- 이는 신규 아이템이 자주 추가되는 영화, 음악, 전자상거래 플랫폼에서 특히 유용함\n",
    "\n",
    "### (4) 단점\n",
    "- 추천 범위의 제한(사용자가 선호한 아이템과 유사한 아이템에 국한).\n",
    "- 신규 사용자 데이터 부족 문제(사용자 선호도 데이터가 없으면 추천 불가).\n",
    "- 다양성 부족(항상 유사한 아이템만 추천, 탐색 부족).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa2748-56b0-41f4-b29c-2cd6e71ba469",
   "metadata": {},
   "source": [
    "\n",
    "## 2. 협업 필터링(Collaborative Filtering)\n",
    "\n",
    "### (1) 특징\n",
    "- 사용자 행동 데이터(평점, 구매 이력 등)를 기반으로 추천.\n",
    "- 사용자와 아이템 간 상호작용 데이터를 활용.\n",
    "- 협업 필터링의 주요 목표는 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가자지 않은 아이템을 예측 평가(Predicted Rating)하는 것\n",
    "- 행(row)은 개별 사용자, 열(col)은 개별 아이템으로 구성, val값은 평점\n",
    "- 일반적으로 희소 행렬(Sparse Matrix) 특성을 가짐.   \n",
    "![image](./recommend.jpeg)\n",
    "- 협업 필터링은 크게 **최근접 이웃 기반**과 **잠재 요인 기반**으로 나뉨.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eac711-eded-4aec-8cf2-f95b86ecbe93",
   "metadata": {},
   "source": [
    "\n",
    "### 2-1. 최근접 이웃(Nearest Neighboring) 협업 필터링\n",
    "\n",
    "#### (1) 특징\n",
    "- 메모리(Memory) 기반 협업 필터링이라고도 불림.\n",
    "- 사용자의 행동 데이터 간 유사도를 계산하여 추천.\n",
    "\n",
    "#### (2) 알고리즘\n",
    "- 유사도 측정 방법: 코사인 유사도, 피어슨 상관계수 등.\n",
    "- **사용자 기반(User-User):** 특정 사용자와 유사한 다른 사용자를 찾아 이들이 선호한 아이템을 추천.\n",
    "    - 당신과 비슷한 고객들이 다음 상품도 구매했습니다.\n",
    "    - 특정 사용자와 유사한 다른 사용자를 Top-N으로 선정해 이 Top-N 사용자가 좋아하는 아이템을 추천하는 방식   \n",
    "    ![image](./user-user.jpeg)  \n",
    "- **아이템 기반(Item-Item):** 특정 아이템과 유사한 다른 아이템을 찾아 추천.\n",
    "    - 이 상품을 선택한 다른 고객들은 다음 상품도 구매했습니다.\n",
    "    - 사용자들이 그 아이템을 좋아하는지/싫어하는지의 평가척도가 유사한 아이템을 추천하는 방식   \n",
    "    - 사용자 기반 최근접 이웃 데이터 세트와 행과 열이 서로 반대임   \n",
    "    ![image](./item-item.jpeg)\n",
    "    - 일반적으로 사용자 기반보다는 아이템 기반 협업 필터링이 정확도가 더 높다. 비슷한 영화를 좋아한다고 해서 취향이 비슷하다고 판단하기는 어렵기 때문. 유명 영화는 취향과 관계 없이 대부분의 사람이 관람하는 경우가 많을 뿐더러, 사용자들이 평점을 매긴 영화의 개수가 많지 않는 경우가 대부분임.\n",
    "\n",
    "#### (3) 장점\n",
    "- 데이터의 명시적 상호작용을 활용하므로 해석이 쉬움.\n",
    "- 아이템 메타데이터 없이도 추천 가능.\n",
    "\n",
    "#### (4) 단점\n",
    "- 희소성 문제(사용자-아이템 행렬의 많은 부분이 비어 있음).\n",
    "- 대규모 데이터셋에서 계산 비용이 큼.\n",
    "- 콜드 스타트 문제(신규 사용자/아이템에 대한 데이터 부족).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef95b38-84cb-4e75-8d40-5e0f43604776",
   "metadata": {},
   "source": [
    "\n",
    "### 2-2. 잠재 요인(Latent Factor) 협업 필터링\n",
    "\n",
    "#### (1) 특징\n",
    "- 사용자-아이템 행렬을 저차원으로 분해하여 숨겨진 패턴(잠재 요인)을 학습.\n",
    "- 대규모 데이터를 처리하기에 적합.\n",
    "\n",
    "#### (2) 알고리즘\n",
    "- 행렬 분해(Matrix Factorization): SVD(Singular Value Decomposition), ALS(Alternating Least Squares), SGD(Stochastic Gradient Descent) 등.\n",
    "- 사용자와 아이템의 잠재 요인 벡터를 학습하여 평점 예측.\n",
    "- 다차원 희소 행렬인 사용자-아이템 행렬 데이터를 저차원 밀집 행렬인 사용자-잠재 요인 행렬과 아이템-잠재 요인 행렬의 전치 행렬로 분해할 수 있으며, 이렇게 분해된 두 행렬의 내적을 통해 새로운 예측 사용자-아이템 평점 행렬 데이터를 만들어서 사용자가 아직 평점을 부여하지 않는 아이템에 대한 예측 평점을 생성함.   \n",
    "![image](./potential.jpeg)  \n",
    "\n",
    "        \n",
    "- '잠재요인'이 무엇인지는 명확하게 정의하기 곤란\n",
    "- R(u, i) : 사용자의 아이템에 대한 평점\n",
    "- P(u, k) : 사용자의 영화 장르별 선호도 행렬\n",
    "- Q(i, k) : 영화별로 여러 장르 요소로 구성된 영화의 장르별 요소 행렬\n",
    "- 평점이란 사용자의 특정 영화 장르에 대한 선호도와 개별 영화의 장르적 특성값을 반영해 결정된다고 생각할 수 있음.\n",
    "- P와 Q를 내적 계산하면 예측 평점을 구할 수 있음  \n",
    "\n",
    "![image](./potential-ex.jpeg)  \n",
    "\n",
    "#### (3) 장점\n",
    "- 희소성 문제를 극복하여 더 정확한 추천 가능.\n",
    "- 대규모 데이터에서도 효과적.\n",
    "\n",
    "#### (4) 단점\n",
    "- 잠재 요인이 무엇인지 해석하기 어려움.\n",
    "- 모델 학습에 시간과 계산 자원이 많이 소요됨.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42813bf4-5e47-44c9-8b38-be274d37a0cc",
   "metadata": {},
   "source": [
    "\n",
    "#### 행렬 분해\n",
    "- 다차원의 매트릭스를 저차원의 매트릭스로 분해하는 기법  \n",
    "- SVD(Singular Vector Decomposition), NMF(Non-Negative Matrix Factorization) 등이 있음  \n",
    "\n",
    "* R = P * Q.T  \n",
    "- M : 사용자 수, N : 아이템 수, K : 잠재요인 차원 수    \n",
    "- R : M x N 차원의 사용자-아이템 평점 행렬\n",
    "- P : M x K 차원의 사용자-잠재요인 행렬  \n",
    "- Q : N x K 차원의 아이템-잠재요인 행렬  \n",
    "\n",
    "![image](./potential-general.jpeg)  \n",
    "- NaN 값을 많이 가지는 고차원 희소행렬인 R 행렬을 저차원 밀집행렬인 P, Q 행렬로 분해  \n",
    "![image](./potential-general2.jpeg)  \n",
    "- NaN값을 유추할 수 있게 됨!  \n",
    "![image](./potential-general3.jpeg)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270166e5-1883-4dd6-af3e-a7161cd4410c",
   "metadata": {},
   "source": [
    "### 1. 대각 행렬 (Diagonal Matrix)\n",
    "#### **정의**\n",
    "- 대각선 요소(왼쪽 위에서 오른쪽 아래)가 아닌 나머지 요소가 모두 0인 행렬을 말함.\n",
    "- 예:\n",
    "  $$\n",
    "  \\Sigma =\n",
    "  \\begin{bmatrix}\n",
    "  \\sigma_1 & 0 & 0 \\\\\n",
    "  0 & \\sigma_2 & 0 \\\\\n",
    "  0 & 0 & \\sigma_3\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "#### **특징**\n",
    "- 행렬의 곱셈과 계산이 간단함.\n",
    "- SVD에서 $\\Sigma$는 행렬의 특이값(Singular Values)을 포함함.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 직교 행렬 (Orthogonal Matrix)\n",
    "#### **정의**\n",
    "- 행 또는 열 벡터가 서로 직교(Orthogonal)하고, 크기가 1로 정규화(Normalized)된 행렬을 말함.\n",
    "- 직교 행렬 $Q$는 $Q^T Q = I$를 만족함.\n",
    "  - $I$: 항등 행렬 (Identity Matrix)\n",
    "  - $Q^T$: $Q$의 전치 행렬 (Transpose)\n",
    "\n",
    "- 예:\n",
    "  $$\n",
    "  U =\n",
    "  \\begin{bmatrix}\n",
    "  1 & 0 \\\\\n",
    "  0 & -1\n",
    "  \\end{bmatrix},\n",
    "  \\quad\n",
    "  V^T =\n",
    "  \\begin{bmatrix}\n",
    "  0.6 & 0.8 \\\\\n",
    "  -0.8 & 0.6\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "#### **특징**\n",
    "- 직교 행렬의 행렬식(Determinant)은 $\\pm 1$.\n",
    "- 길이를 유지하는 선형 변환(유니타리 변환)을 나타냄.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. 비음수 행렬 (Non-Negative Matrix)\n",
    "#### **정의**\n",
    "- 모든 요소가 0 또는 양수인 행렬을 말함.\n",
    "- 예:\n",
    "  $$\n",
    "  W =\n",
    "  \\begin{bmatrix}\n",
    "  1 & 0.5 \\\\\n",
    "  0.3 & 0.7\n",
    "  \\end{bmatrix},\n",
    "  \\quad\n",
    "  H =\n",
    "  \\begin{bmatrix}\n",
    "  0.6 & 0.4 \\\\\n",
    "  0.8 & 0.9\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "#### **특징**\n",
    "- 음수 값을 허용하지 않기 때문에, 물리적 해석이 쉬움(예: 픽셀 강도, 평점 등).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b7258-6a8f-4ad8-b8ed-ca6372b9a7bd",
   "metadata": {},
   "source": [
    "\n",
    "### 4. SVD와 행렬 분해 원리\n",
    "\n",
    "#### **SVD 정의**\n",
    "SVD는 다음과 같이 행렬을 세 부분으로 분해함:\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "- $A$: 원본 행렬.\n",
    "- $U$, $V^T$: 직교 행렬로, 각각 **왼쪽 특이 벡터(Left Singular Vectors)**와 **오른쪽 특이 벡터(Right Singular Vectors)**를 나타냄.\n",
    "- $\\Sigma$: 대각 행렬로, 행렬의 **특이값(Singular Values)**을 나타냄.\n",
    "\n",
    "#### **SVD의 작동 원리**\n",
    "1. **특이값(Singular Values) 계산**:\n",
    "   - 행렬 $A$의 특이값은 $A^T A$ 또는 $A A^T$의 고유값(Eigenvalues)을 통해 계산함.\n",
    "   - 이 값들은 데이터의 분산을 나타냄.\n",
    "\n",
    "2. **특이 벡터(Singular Vectors) 계산**:\n",
    "   - $A^T A$의 고유벡터는 $V$를 형성.\n",
    "   - $A A^T$의 고유벡터는 $U$를 형성.\n",
    "\n",
    "3. **분해 과정**:\n",
    "   - $A$를 $U$, $\\Sigma$, $V^T$로 분해하여 데이터의 차원을 줄이거나 중요한 요소를 추출할 수 있음.\n",
    "\n",
    "#### **분리 결과**\n",
    "- $U$: 원본 데이터의 주요 축(Principal Axes)을 나타냄.\n",
    "- $\\Sigma$: 주요 축에서의 중요도를 나타냄.\n",
    "- $V^T$: 원본 데이터의 패턴을 나타냄.\n",
    "\n",
    "\n",
    "\n",
    "- SVD는 NaN값이 없는 행렬에만 적용 가능\n",
    "- NaN 값이 있는 경우 결측값 대체, [확률적 경사 하강법(SGD, Stochastic Gradient Descent)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) 이나 [ALS(Alternating Least Squares)](https://blog.firstpenguine.school/4) 방식을 이용해 SVD를 수행할 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c6c06-f0fe-4e84-a334-77dc83620b8e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 5. NMF와 행렬 분해 원리\n",
    "\n",
    "#### **NMF 정의**\n",
    "NMF는 다음과 같이 행렬을 두 부분으로 분해함:\n",
    "$$\n",
    "A \\approx WH\n",
    "$$\n",
    "\n",
    "- $A$: 원본 행렬.\n",
    "- $W$: 데이터의 기저(Basis)를 나타내는 비음수 행렬.\n",
    "- $H$: 기저의 가중치(Weights)를 나타내는 비음수 행렬.\n",
    "\n",
    "#### **NMF의 작동 원리**\n",
    "1. **목적 함수 설정**:\n",
    "   - $||A - WH||^2$를 최소화하는 $W$와 $H$를 찾음.\n",
    "   - 비음수 조건(Non-negativity Constraint)을 강제로 부여하여 양수 해를 구함.\n",
    "\n",
    "2. **최적화 과정**:\n",
    "   - 경사 하강법(Gradient Descent) 또는 곱셈 업데이트 규칙(Multiplicative Update Rule)을 사용하여 $W$와 $H$를 반복적으로 업데이트.\n",
    "   - 예:\n",
    "     $$\n",
    "     W_{ij} \\leftarrow W_{ij} \\frac{(A H^T)_{ij}}{(W H H^T)_{ij}}\n",
    "     $$\n",
    "     $$\n",
    "     H_{ij} \\leftarrow H_{ij} \\frac{(W^T A)_{ij}}{(W^T W H)_{ij}}\n",
    "     $$\n",
    "\n",
    "3. **수렴 조건**:\n",
    "   - $||A - WH||^2$가 더 이상 줄어들지 않으면 분해 종료.\n",
    "\n",
    "#### **분리 결과**\n",
    "- $W$: 원본 데이터를 구성하는 기본 패턴.\n",
    "- $H$: 각 패턴이 데이터에서 차지하는 비중.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110ce1d-fcf9-48c8-9fa1-18e30bee6a48",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 6. SVD와 NMF의 차이점\n",
    "\n",
    "| **특징**          | **SVD**                                          | **NMF**                                    |\n",
    "|--------------------|-------------------------------------------------|-------------------------------------------|\n",
    "| **분해 형태**     | $A = U \\Sigma V^T$                              | $A \\approx WH$                            |\n",
    "| **음수 데이터 허용** | 허용                                            | 허용하지 않음                              |\n",
    "| **주요 응용**      | 차원 축소, 데이터 압축, 추천 시스템             | 문서 군집화, 추천 시스템, 이미지 분해      |\n",
    "| **분해의 해석성**   | 해석이 어렵거나 음수 값 포함                   | 해석이 쉬움 (양수 값만 포함)              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e74a48-a99b-433d-ac12-b68fa7208699",
   "metadata": {},
   "source": [
    "\n",
    "## 3. 하이브리드 필터링(Hybrid Filtering)\n",
    "\n",
    "### (1) 특징\n",
    "- 콘텐츠 기반 필터링과 협업 필터링을 결합하여 단점을 보완.\n",
    "- 추천의 다양성과 정확도를 모두 높임.\n",
    "\n",
    "### (2) 알고리즘\n",
    "- **가중 평균(Weighted Sum):** 두 필터링 방식의 결과를 가중 평균하여 계산.\n",
    "- **전환 모델(Switching):** 상황에 따라 적합한 필터링 방식 선택.\n",
    "- **혼합 모델(Mixture Model):** 두 방식을 결합한 새로운 모델 학습.\n",
    "\n",
    "### (3) 장점\n",
    "- 콘텐츠 기반 필터링과 협업 필터링의 단점을 상호 보완.\n",
    "- 다양한 사용자와 아이템에 대해 균형 잡힌 추천 가능.\n",
    "\n",
    "### (4) 단점\n",
    "- 구현 복잡도가 증가.\n",
    "- 데이터 통합 및 모델 조정에 시간과 비용 소요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b4096-2a21-4ac4-8c65-7bb232df180d",
   "metadata": {},
   "source": [
    "\n",
    "## 4. 딥러닝 기반 추천 시스템(Deep Learning-Based Recommendation Systems)\n",
    "\n",
    "### (1) 특징\n",
    "- 딥러닝을 활용해 사용자 행동 데이터와 아이템 데이터를 복합적으로 분석.\n",
    "- 비정형 데이터(텍스트, 이미지 등)와 정형 데이터의 결합 가능.\n",
    "\n",
    "### (2) 알고리즘\n",
    "- CNN(Convolutional Neural Network)으로 이미지 기반 특성 학습.\n",
    "- RNN(Recurrent Neural Network)으로 시퀀스 데이터 분석.\n",
    "- 트랜스포머 모델로 사용자 리뷰 텍스트 데이터를 분석.\n",
    "\n",
    "### (3) 장점\n",
    "- 대규모 데이터에서 더 정교한 패턴 학습 가능.\n",
    "- 비정형 데이터까지 활용 가능하여 추천 정확도 향상.\n",
    "\n",
    "### (4) 단점\n",
    "- 데이터 및 계산 자원이 많이 필요.\n",
    "- 모델 학습 및 최적화 과정이 복잡.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b084da0-7853-4999-b055-39ab939560ea",
   "metadata": {},
   "source": [
    "\n",
    "## 5. 연관 규칙(Association Rule)\n",
    "\n",
    "### (1) 특징\n",
    "- 사용자가 함께 구매한 상품 간의 관계를 분석하여 추천.\n",
    "- 장바구니 분석(Market Basket Analysis)에 주로 사용.\n",
    "\n",
    "### (2) 알고리즘\n",
    "- Apriori, FP-Growth 알고리즘을 사용해 연관 규칙 학습.\n",
    "- 상품 간 연관도를 계산하여 추천.\n",
    "\n",
    "### (3) 장점\n",
    "- 간단한 계산으로 연관 관계를 도출.\n",
    "- 특정 상품군에서 효과적.\n",
    "\n",
    "### (4) 단점\n",
    "- 희소성 문제 발생.\n",
    "- 정교한 개인화 추천에는 한계.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7e875-6e6e-4014-bc29-4be1bbdcdd34",
   "metadata": {},
   "source": [
    "\n",
    "## 5. 연관 규칙(Association Rule)\n",
    "\n",
    "### (1) 특징\n",
    "- 사용자가 함께 구매한 상품 간의 관계를 분석하여 추천.\n",
    "- 장바구니 분석(Market Basket Analysis)에 주로 사용.\n",
    "\n",
    "### (2) 알고리즘\n",
    "- Apriori, FP-Growth 알고리즘을 사용해 연관 규칙 학습.\n",
    "- 상품 간 연관도를 계산하여 추천.\n",
    "\n",
    "### (3) 장점\n",
    "- 간단한 계산으로 연관 관계를 도출.\n",
    "- 특정 상품군에서 효과적.\n",
    "\n",
    "### (4) 단점\n",
    "- 희소성 문제 발생.\n",
    "- 정교한 개인화 추천에는 한계.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a21fbb-8126-40ba-b028-19a318bca22d",
   "metadata": {},
   "source": [
    "\n",
    "## 6. 통계 기반 추천(Statistical Recommendation)\n",
    "\n",
    "### (1) 특징\n",
    "- 사용자 행동 데이터를 기반으로 평균값, 상관계수 등 통계적 지표를 활용하여 추천.\n",
    "- 간단한 수학적 기법으로 구현 가능.\n",
    "\n",
    "### (2) 알고리즘\n",
    "- 사용자의 클릭, 구매 데이터를 수집하여 통계적으로 분석.\n",
    "- 특정 기준(평균 평점, 인기 아이템) 기반으로 추천 생성.\n",
    "\n",
    "### (3) 장점\n",
    "- 구현이 간단하며 적은 데이터로도 활용 가능.\n",
    "- 빠르게 결과를 제공할 수 있음.\n",
    "\n",
    "### (4) 단점\n",
    "- 개인화 추천에 한계.\n",
    "- 데이터의 품질이 낮으면 정확도가 떨어짐.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
